\documentclass[a4paper, 12pt]{scrartcl}
% A4 Papier, 12pt Schriftgröße
% scriptartcl, weil article für englischsprachigen Raum optimiert



% --- EINSTELLUNGEN FÜR DEUTSCHE DOKUMENTE:
\usepackage[ngerman]{babel}
% new german (neue deutsche Rechtschreibung)

\usepackage[utf8]{inputenc}
% utf8-Eingabe (Umlaute etc...)

\usepackage[T1]{fontenc}
% damit im erstellten PDF auch nach Wörtern mit Umlauten gesucht werden kann

\usepackage{csquotes}
% für deutsche Anführungsstriche

\title{End-to-end-Learning Ansatz für autonomes Fahren im Miniatur Wunderland}
\author{Nils-Ole Bickel, Michel Brüger}
\date{\today}

\begin{document}
	
\maketitle
% Erstellt den Titel, entsprechend den Angaben in der Präambel
	
\tableofcontents
% Automatisch erstelltes Inhaltsverzeichnis
% zweimal kompilieren, damit Änderungen korrekt angezeigt werden

\newpage
% neue Seite anfangen, damit Titel und Inhaltsverzeichnis auf eigener Seite stehen
	
	\begin{abstract}
ToDo: 

evtl Abstract schreiben	

- end-to-end learning erklären

-- netzt sagt für übertragene Bilder lenkwinkel voraus

-- übermittelte Lenkwinkel als Label, Netz sagt für übertragene Bilder Lenkwinkel voraus
	\end{abstract}

	\section{Hardware}
		\subsection{Raspberry Pi 4}
		Die Hardware in dem Fahrzeug selbst ist nicht stark genug um aus den Kamerabildern den entsprechenden Lenkwinkel zu berechnen. Daher ist das Ziel, die Berechnung der Lenkwinkel auszulagern, auf einen Rechner, der im besten Fall unauffällig im \emph{Miniaturwunderland} "getarnt" werden kann. 
		
		Der \emph{Raspberry Pi 4} hat im Verhältnis zu seiner Größe potente Hardware und verfügt vor allem auch über zwei USB-3-Anschlüsse. Diese sind wichtig um das volle Potential aus dem \emph{Google Coral USB Accelerator} herauszuholen. Außerdem bietet er die Möglichkeit vollwertige Linux-Betriebssysteme zu installieren, was die Verwendung der für die AI-Lenkwinkel-Voraussagung notwendigen Software ermöglicht.
		
		Die Möglichkeit, den \emph{Raspberry Pi} über eine Powerbank per USB-C zu laden, macht es noch leichter ihn in der Kulisse zu verstecken, da man nicht noch ein Kabel zu einem Stromanschluss verlegen muss.
		
		
		\subsection{Google Coral USB Accelerator}
		Der \emph{Google Coral USB Accelerator} ist ein Tensor-Prozessor in Form eines USB-Sticks, der an einen Rechner wie den \emph{Raspberry Pi} angeschlossen werden kann, um die Machine Learning Operationen schnell und besonders energieeffizient durchzuführen. Dies kann der \emph{Raspberry Pi 4} zwar auch alleine bewerkstelligen, der \emph{Google Coral USB Accelerator} ist dabei aber deutlich schneller. Bei spontanen Vergleichen konnten wir eine 14-fache Geschwindigkeit bei der Objekterkennung in Bildern feststellen.
		
		
		\subsection{Das Auto}
		\textbf{\textit{\underline{darüber wissen wir eigentlich nichts, vielleicht Section lieber wieder löschen?}}}
	
	
		\subsection{Der Trainingsrechner}
		Das Netz wurde Trainiert auf einem der Laborrechner in Raum \textbf{\textit{\underline{???}}}. Dieser verfügt über einen \textbf{\textit{\underline{???}}} Prozessor und eine \emph{Nvidia Geforce GTX 1050 Ti} Grafikkarte, welche den Trainingsprozess deutlich beschleunigt, im Vergleich zum Training mit dem Prozessor.	
	
	\section{Software}
		\subsection{Auf dem Raspberry Pi verwendete Software}
			\subsubsection{Raspbian}
			Als Betriebssystem auf dem \emph{Raspberry Pi 4} wird \emph{Raspbian Buster} verwendet. Dabei handelt es sich um eine auf Debian basierende Linux-Distribution.
			
			
			\subsubsection{Python}
			Standardmäßig ist \emph{Python 3.7} in \emph{Raspbian Buster} enthalten. Dies ist für die Verwendung des \emph{Google Coral USB Accelerator} mit \emph{Tensorflow Lite} ausreichend.
			
			\subsubsection{Edge TPU runtime}
			Die \emph{Edge TPU runtime} wird für die Kommunikation mit dem \emph{Google Coral USB Accelerator} benötigt.
			
			Während der Installation der \emph{Edge TPU runtime} kann man auswählen, ob man den \emph{Google Coral USB Accelerator} mit Standardgeschwindigkeit oder maximaler Geschwindigkeit (2x Standard) betreiben möchte. Da sich bei unseren Versuchen mit Standardgeschwindigkeit herausgestellt hat, dass der \emph{Raspberry Pi 4} bei der Vorbereitung der Bilder überhitzt, ist eine Installation mit maximaler Geschwindigkeit überflüssig.
			
			\subsubsection{Tensorflow Lite}
			
			
			
		\subsection{Auf dem Auto verwendete Software}
		- irgendwie schickt es einen Videostream...
		\subsection{Auf dem Trainingsrechner verwendete Software}
			\subsubsection{Anaconda}
			- Virtual Environments \\
			- Python \\
			- Tensorflow \\
			- Tensorflow lite converter (heisst der so?) \\
			
		\section{Das Netz}
			\subsection{Implementierung}
			Das Netzwerk besteht aus 11 Layern. Bei 6 davon handelt es sich um Convolutional Layer. Die anderen 5 sind fully-connected Layer. Die Convolutional Layer sind für die Featureerkennunng verantwortlich. Die ersten 4 haben einen Kernel der Größe 5x5 und Strides der Größe 2x2. Die anderen Convolutional Layer haben einen Kernen der Größe 3x3 und Strides der Größe 1x1. Anschließend kommen die 5 fully-connnnected Layer. Das als Ergebnis beschreibt den Lenkwinkel in einer abstrakten Form. Genauer ist es die Länge des Vektors (X, Y), die der Hall Sensor, an der Vorderachse des Auto, bei diesem Lenkeinschlag misst.\\ \\
			Als Vorlage für das Netzwerk wurde das Netzwerk aus dem Paper [1] verwendet. Unsere Bilder haben eine Größe von 300x800. Dies ist deutlich größer als im Paper weshalb das Netzwerk um weitere Layer ergenzt wurde.
			
			\subsection{Training}
				\subsubsection{Trainingsdaten}
				Die Trainingsdaten wurden mit Hilfe des Autos aufgenommen. Das Auto ist entlang eines Drahtes nach dem Faller Car-System durch das Miniatur Wunderland gefahren. Dabei wurden Video-Stream und zugehörige Werte des Hall Sensors aufgezeichnet. Die obere Hälfte des Bildausschnitts wird verworfen. Dies führt dazu, dass großteils die Straße auf den Bildern zu sehen ist. Die Hoffnung ist, dass dadurch das Netzwerk nicht durch Häuser oder Deckenelemente im Miniatur Wunderland abgelenkt wird und somit allgemeiner eingesetzt werden kann. \\ \\
				Die Bilder werden als BGR-Bilder mit 3 Kanälen zusammen mit den Daten zum Lenkwinkel in einer H5-Datei gespeichert. Dabei ist zu beachten, dass die Bilddaten bereits als float32 Werte gespeichert werden. Sonnst muss dieser rechenaufwändige Schritt während des Trainings durchgeführt werden. Eine Normierung der Bilddaten auf einen Wert zwischen 0 und 1 könnte zu einer Verbesserung der Ergebnisse vom Netzwerk führen. Allerdings würde es auf die Zeit, bis ein Bild bearbeitet wurde deutlich erhöhen, weshalb wir uns dagegen entschieden haben.
				\subsubsection{Optimierung}
				Das Netzwerk wird dahingehend Trainiert die durchschnittlichen Quadratischen Abweichung (mse) zwischen dem Ergebnis des Netzes und den gemessenen Daten zum Lenkwinkel zu minimieren. Dies führt dazu, dass große Abweichungen besonders stark Gewichtet werden und kleinere nur Geringer. 
				\subsubsection{...}
			
	\section{Ergebnisse/Fazit}
	- Genauigkeit der Berechneten Lenkwinkel noch nicht erprobt...
\end{document}